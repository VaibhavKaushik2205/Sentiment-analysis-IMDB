{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = pd.read_csv('IMDB Dataset.csv')\n",
    "tokenizer = TreebankWordTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = 12500\n",
    "\n",
    "reviews_train = []\n",
    "\n",
    "for review in reviews['review']:\n",
    "    reviews_train.append(review)\n",
    "\n",
    "reviews_test = reviews_train[val:]    \n",
    "reviews_train = reviews_train[:val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Clean Reviews\n",
    "\n",
    "import re\n",
    "\n",
    "REPLACE_NO_SPACE = re.compile(\"[.;:!\\'?,\\\"()\\[\\]]\")\n",
    "REPLACE_WITH_SPACE = re.compile(\"(<br\\s*/><br\\s*/>)|(\\-)|(\\/)\")\n",
    "\n",
    "def preprocess_reviews(reviews):\n",
    "    reviews = [REPLACE_NO_SPACE.sub(\"\", line.lower()) for line in reviews]\n",
    "    reviews = [REPLACE_WITH_SPACE.sub(\" \", line) for line in reviews]\n",
    "    \n",
    "    return reviews\n",
    "\n",
    "reviews_train = preprocess_reviews(reviews_train)\n",
    "reviews_test = preprocess_reviews(reviews_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "english_stop_words = stopwords.words('english')\n",
    "def remove_stop_words(corpus):\n",
    "    removed_stop_words = []\n",
    "    for review in corpus:\n",
    "        removed_stop_words.append(\n",
    "            ' '.join([word for word in review.split() \n",
    "                      if word not in english_stop_words])\n",
    "        )\n",
    "    return removed_stop_words\n",
    "\n",
    "reviews_train = remove_stop_words(reviews_train)\n",
    "reviews_test = remove_stop_words(reviews_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Stemmed Reviews\n",
    "\n",
    "def get_stemmed_text(corpus):\n",
    "    from nltk.stem.porter import PorterStemmer\n",
    "    stemmer = PorterStemmer()\n",
    "    return [' '.join([stemmer.stem(word) for word in review.split()]) for review in corpus]\n",
    "\n",
    "stemmed_reviews_train = get_stemmed_text(reviews_train)\n",
    "stemmed_reviews_test = get_stemmed_text(reviews_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lemmatized Reviews\n",
    "\n",
    "def get_lemmatized_text(corpus):\n",
    "    from nltk.stem import WordNetLemmatizer\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    return [' '.join([lemmatizer.lemmatize(word) for word in review.split()]) for review in corpus]\n",
    "\n",
    "lemmatized_reviews_train = get_lemmatized_text(reviews_train)\n",
    "lemmatized_reviews_test = get_lemmatized_text(reviews_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nngrams_lemmatized = pd.DataFrame(\\n             lemmatized_features.todense(),\\n             columns=tfidf.get_feature_names())\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(min_df=5, ngram_range=(1,2))\n",
    "\n",
    "## Without Normalisation\n",
    "tfidf.fit(reviews_train)\n",
    "features_train = tfidf.transform(reviews_train)\n",
    "features_test = tfidf.transform(reviews_test)\n",
    "\n",
    "## Stemmed Features\n",
    "tfidf.fit(stemmed_reviews_train)\n",
    "stemmed_features_train = tfidf.transform(stemmed_reviews_train)\n",
    "stemmed_features_test = tfidf.transform(stemmed_reviews_test)\n",
    "\n",
    "'''\n",
    "ngrams_stemmed = pd.DataFrame(\n",
    "             stemmed_features.todense(),\n",
    "             columns=tfidf.get_feature_names())\n",
    "'''\n",
    "\n",
    "## lemmatized Features\n",
    "tfidf.fit(lemmatized_reviews_train)\n",
    "lemmatized_features_train = tfidf.transform(lemmatized_reviews_train)\n",
    "lemmatized_features_test = tfidf.transform(lemmatized_reviews_test)\n",
    "\n",
    "'''\n",
    "ngrams_lemmatized = pd.DataFrame(\n",
    "             lemmatized_features.todense(),\n",
    "             columns=tfidf.get_feature_names())\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sentiments\n",
    "target = []\n",
    "for sentiment in reviews['sentiment'] :\n",
    "    if sentiment == 'positive' :\n",
    "        target.append(1)\n",
    "    else :\n",
    "        target.append(0)\n",
    "\n",
    "target_train = target[:val]\n",
    "target_test = target[val:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Without Normalisation\n",
      "Accuracy for C=0.01: 0.80416\n",
      "Accuracy for C=0.05: 0.85376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vaibhav/my_project_dir/my_project_env/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2179: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n",
      "/home/vaibhav/my_project_dir/my_project_env/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for C=0.25: 0.8736\n",
      "Accuracy for C=0.5: 0.88192\n",
      "Accuracy for C=1: 0.89056\n",
      "\n",
      "After Stemming\n",
      "Accuracy for C=0.01: 0.77184\n",
      "Accuracy for C=0.05: 0.82848\n",
      "Accuracy for C=0.25: 0.85568\n",
      "Accuracy for C=0.5: 0.86496\n",
      "Accuracy for C=1: 0.87104\n",
      "\n",
      "After Lemmatizing\n",
      "Accuracy for C=0.01: 0.82464\n",
      "Accuracy for C=0.05: 0.83776\n",
      "Accuracy for C=0.25: 0.8624\n",
      "Accuracy for C=0.5: 0.86912\n",
      "Accuracy for C=1: 0.8752\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "print ('\\nWithout Normalisation')\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "   features_train , target_train, train_size = 0.75\n",
    ")\n",
    "\n",
    "for c in [0.01, 0.05, 0.25, 0.5, 1]:\n",
    "    \n",
    "    lr = LogisticRegression(C=c)\n",
    "    lr.fit(X_train, y_train)\n",
    "    print (\"Accuracy for C=%s: %s\" \n",
    "           % (c, accuracy_score(y_val, lr.predict(X_val))))\n",
    "\n",
    "\n",
    "print ('\\nAfter Stemming')\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    stemmed_features_train, target_train, train_size = 0.75\n",
    ")\n",
    "\n",
    "for c in [0.01, 0.05, 0.25, 0.5, 1]:\n",
    "    \n",
    "    lr = LogisticRegression(C=c)\n",
    "    lr.fit(X_train, y_train)\n",
    "    print (\"Accuracy for C=%s: %s\" \n",
    "           % (c, accuracy_score(y_val, lr.predict(X_val))))\n",
    "\n",
    "print ('\\nAfter Lemmatizing')\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    lemmatized_features_train, target_train, train_size = 0.75\n",
    ")\n",
    "\n",
    "for c in [0.01, 0.05, 0.25, 0.5, 1]:\n",
    "    \n",
    "    lr = LogisticRegression(C=c)\n",
    "    lr.fit(X_train, y_train)\n",
    "    print (\"Accuracy for C=%s: %s\" \n",
    "           % (c, accuracy_score(y_val, lr.predict(X_val))))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Accuracy: Un-Normalized : 0.8854133333333334\n",
      "Final Accuracy: After Stemming : 0.8831466666666666\n",
      "Final Accuracy: After Lemmatizing : 0.88424\n"
     ]
    }
   ],
   "source": [
    "## Final Model for Without Normalization\n",
    "\n",
    "final_ngram = LogisticRegression(C=1)\n",
    "final_ngram.fit(features_train, target_train)\n",
    "print (\"Final Accuracy: Un-Normalized : %s\" \n",
    "       % accuracy_score(target_test, final_ngram.predict(features_test)))\n",
    "\n",
    "## Final Model for Stemmed Features\n",
    "final_ngram = LogisticRegression(C=1)\n",
    "final_ngram.fit(stemmed_features_train, target_train)\n",
    "print (\"Final Accuracy: After Stemming : %s\" \n",
    "       % accuracy_score(target_test, final_ngram.predict(stemmed_features_test)))\n",
    "\n",
    "## Final Model for Lemaatized Features\n",
    "final_ngram = LogisticRegression(C=1)\n",
    "final_ngram.fit(lemmatized_features_train, target_train)\n",
    "print (\"Final Accuracy: After Lemmatizing : %s\" \n",
    "       % accuracy_score(target_test, final_ngram.predict(lemmatized_features_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best\n",
      "('great', 6.337722195219969)\n",
      "('excellent', 4.826326775322904)\n",
      "('best', 3.9339454568666197)\n",
      "('wonderful', 3.8203331514044727)\n",
      "('love', 3.7307311970448076)\n",
      "\n",
      "Worst\n",
      "('bad', -7.525844348565642)\n",
      "('worst', -5.975479130380973)\n",
      "('awful', -5.158488033413389)\n",
      "('waste', -4.689547560583586)\n",
      "('boring', -4.674836702585414)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## Get Best and Worst Features\n",
    "feature_to_coef = {\n",
    "    word: coef for word, coef in zip(\n",
    "        tfidf.get_feature_names(), final_ngram.coef_[0]\n",
    "    )\n",
    "}\n",
    "\n",
    "## Best Reviews\n",
    "print ('Best')\n",
    "for best_positive in sorted(\n",
    "    feature_to_coef.items(), \n",
    "    key=lambda x: x[1], \n",
    "    reverse=True)[:5]:\n",
    "    print (best_positive)\n",
    "\n",
    "    \n",
    "## Worst Reiviews \n",
    "print ('\\nWorst')\n",
    "for best_negative in sorted(\n",
    "    feature_to_coef.items(), \n",
    "    key=lambda x: x[1])[:5]:\n",
    "    print (best_negative)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note: Try different Models and check accuracy in them to see which is better"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
